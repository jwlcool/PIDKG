from __future__ import print_function
from __future__ import absolute_import
from __future__ import division
import numpy as np
import argparse
import os


# dataset='music'
# dataset='Taobao'
dataset='Taobao_Big'
# dataset='movie'


if dataset=='movie':
    cmd_opt = argparse.ArgumentParser(description='Argparser for coevolve')
    cmd_opt.add_argument('--dataset', type=str, default='movie-1m', help='which dataset to use')
    cmd_opt.add_argument('--aggregator', type=str, default='sum', help='which aggregator to use')
    cmd_opt.add_argument('--n_epochs', type=int, default=10, help='the number of epochs')
    cmd_opt.add_argument('--neighbor_sample_size', type=int, default=4, help='the number of neighbors to be sampled')
    cmd_opt.add_argument('--dim', type=int, default=32, help='dimension of user and entity embeddings')
    cmd_opt.add_argument('--n_iter', type=int, default=2, help='number of iterations when computing entity representation')
    cmd_opt.add_argument('--l2_weight', type=float, default=1e-7, help='weight of l2 regularization')
    cmd_opt.add_argument('--lr', type=float, default=2e-2, help='learning rate')
    cmd_opt.add_argument('--ratio', type=float, default=1, help='size of training dataset')
    cmd_opt.add_argument('-train_file', default='../data/movie-1m/train.txt', help='train_file')
    cmd_opt.add_argument('-test_file', default='../data/movie-1m/test.txt', help='test_file')
    cmd_opt.add_argument('-kg_user', default=True, help='kg_user')
    cmd_opt.add_argument('-kg_item', default=True, help='kg_item')

    cmd_opt.add_argument('-metapath', default=True, help='metapath')
    cmd_opt.add_argument('-tbatch', type=int, default=100, help='tbatch')
    cmd_opt.add_argument('-weight_ratio', default=0.1, type=float, help='weight_ratio')

    cmd_opt.add_argument('-save_dir', default='.', help='result output root')
    cmd_opt.add_argument('-dropbox', default=None, help='dropbox folder')
    cmd_opt.add_argument('-init_model_dump', default=None, help='model dump')
    cmd_opt.add_argument('-data_name', default=None, help='dataset name')
    cmd_opt.add_argument('-phase', default=None, help='phase')
    cmd_opt.add_argument('-dt_type', default='last', help='last/cur')
    cmd_opt.add_argument('-int_act', default='sigmoid', help='activation function for intensity', choices=['exp', 'softplus','sigmoid'])
    cmd_opt.add_argument('-score_func', default='log_ll', help='log_ll/comp/intensity')
    cmd_opt.add_argument('-is_training', default=True, type=eval, help='is training')
    cmd_opt.add_argument('-embed_dim', default=128, type=int, help='embedding dim of gnn')
    cmd_opt.add_argument('-bptt', default=100, type=int, help='bptt size')
    cmd_opt.add_argument('-num_items', default=0, type=int, help='num items')
    cmd_opt.add_argument('-num_users', default=0, type=int, help='num users')
    cmd_opt.add_argument('-maxitem', default=0, type=int, help='max item')
    cmd_opt.add_argument('-maxuser', default=0, type=int, help='max user')
    cmd_opt.add_argument('-neg_items', default=100, type=int, help='neg items')
    cmd_opt.add_argument('-neg_users', default=100, type=int, help='neg users')
    cmd_opt.add_argument('-max_norm', default=0.1, type=float, help='max embed norm')
    cmd_opt.add_argument('-time_scale', default=0.001, type=float, help='time scale')
    cmd_opt.add_argument('-time_lb', default=0.01, type=float, help='min time dur')
    cmd_opt.add_argument('-time_ub', default=0.1, type=float, help='max time dur')
    cmd_opt.add_argument('-seed', default=19260817, type=int, help='seed')
    cmd_opt.add_argument('-learning_rate', default=0.0001, type=float, help='learning rate')
    cmd_opt.add_argument('-grad_clip', default=5, type=float, help='clip gradient')
    cmd_opt.add_argument('-num_epochs', default=1000, type=int, help='number of training epochs')
    cmd_opt.add_argument('-iters_per_val', default=100, type=int, help='number of iterations per evaluation')
    cmd_opt.add_argument('-batch_size', default=64, type=int, help='batch size for training')
    cmd_opt.add_argument('-eval_ratio', default=0, type=float, help='eval_ratio')
    cmd_opt.add_argument('-test_ratio', default=0.3, type=float, help='test_ratio')
    cmd_opt.add_argument('-act', '--act', type=str, help='act function', default='tanh')
    cmd_opt.add_argument('-hop', default=1, type=int, help='hop')
    cmd_opt.add_argument('-path_len', type=int, default=3, help='path_len')
    cmd_opt.add_argument('-path_sample_size', type=int, default=4, help='path_sample_size')
    cmd_args, _ = cmd_opt.parse_known_args()

# music
if dataset=='music':
    cmd_opt = argparse.ArgumentParser(description='Argparser for coevolve')
    cmd_opt.add_argument('--dataset', type=str, default='music', help='which dataset to use')
    cmd_opt.add_argument('--aggregator', type=str, default='sum', help='which aggregator to use')
    cmd_opt.add_argument('--n_epochs', type=int, default=10, help='the number of epochs')
    cmd_opt.add_argument('--neighbor_sample_size', type=int, default=8, help='the number of neighbors to be sampled')
    cmd_opt.add_argument('--dim', type=int, default=16, help='dimension of user and entity embeddings')
    cmd_opt.add_argument('--n_iter', type=int, default=1, help='number of iterations when computing entity representation')
    cmd_opt.add_argument('--batch_size', type=int, default=128, help='batch size')
    cmd_opt.add_argument('--l2_weight', type=float, default=1e-4, help='weight of l2 regularization')
    cmd_opt.add_argument('--lr', type=float, default=5e-4, help='learning rate')
    cmd_opt.add_argument('--ratio', type=float, default=1, help='size of training dataset')
    cmd_opt.add_argument('-train_file', default='../data/music/train.txt', help='train_file')
    cmd_opt.add_argument('-test_file', default='../data/music/test.txt', help='test_file')
    cmd_opt.add_argument('-kg_user', default=True, help='kg_user')
    cmd_opt.add_argument('-kg_item', default=True, help='kg_item')

    cmd_opt.add_argument('-metapath', default=True, help='metapath')
    cmd_opt.add_argument('-tbatch', type=int,default=0, help='tbatch')
    cmd_opt.add_argument('-weight_ratio', default=0.4, type=float, help='weight_ratio')
    cmd_opt.add_argument('-neighbor_ratio', default=0.3, type=float, help='neighbor_ratio')

    cmd_opt.add_argument('-save_dir', default='.', help='result output root')
    cmd_opt.add_argument('-dropbox', default=None, help='dropbox folder')
    cmd_opt.add_argument('-init_model_dump', default=None, help='model dump')
    cmd_opt.add_argument('-data_name', default=None, help='dataset name')
    cmd_opt.add_argument('-phase', default=None, help='phase')
    cmd_opt.add_argument('-dt_type', default='last', help='last/cur')
    cmd_opt.add_argument('-int_act', default='exp', help='activation function for intensity', choices=['exp', 'softplus','sigmoid'])
    cmd_opt.add_argument('-score_func', default='log_ll', help='log_ll/comp/intensity')
    cmd_opt.add_argument('-is_training', default=True, type=eval, help='is training')
    cmd_opt.add_argument('-embed_dim', default=10, type=int, help='embedding dim of gnn')
    cmd_opt.add_argument('-bptt', default=100, type=int, help='bptt size')
    cmd_opt.add_argument('-num_items', default=0, type=int, help='num items')
    cmd_opt.add_argument('-num_users', default=0, type=int, help='num users')
    cmd_opt.add_argument('-maxitem', default=0, type=int, help='max item')
    cmd_opt.add_argument('-maxuser', default=0, type=int, help='max user')
    cmd_opt.add_argument('-neg_items', default=100, type=int, help='neg items')
    cmd_opt.add_argument('-neg_users', default=100, type=int, help='neg users')
    cmd_opt.add_argument('-max_norm', default=0.1, type=float, help='max embed norm')
    cmd_opt.add_argument('-time_scale', default=0.001, type=float, help='time scale')
    cmd_opt.add_argument('-time_lb', default=0.01, type=float, help='min time dur')
    cmd_opt.add_argument('-time_ub', default=0.1, type=float, help='max time dur')
    cmd_opt.add_argument('-seed', default=19260817, type=int, help='seed')
    cmd_opt.add_argument('-learning_rate', default=0.00001, type=float, help='learning rate')
    cmd_opt.add_argument('-grad_clip', default=5, type=float, help='clip gradient')
    cmd_opt.add_argument('-num_epochs', default=1000, type=int, help='number of training epochs')
    cmd_opt.add_argument('-iters_per_val', default=100, type=int, help='number of iterations per evaluation')
    cmd_opt.add_argument('-batch_size', default=64, type=int, help='batch size for training')
    cmd_opt.add_argument('-eval_ratio', default=0, type=float, help='eval_ratio')
    cmd_opt.add_argument('-test_ratio', default=0.3, type=float, help='test_ratio')
    cmd_opt.add_argument('-act', '--act', type=str, help='act function', default='tanh')
    cmd_opt.add_argument('-hop', default=1, type=int, help='hop')
    cmd_opt.add_argument('-path_len', type=int, default=3, help='path_len')
    cmd_opt.add_argument('-path_sample_size', type=int, default=4, help='path_sample_size')
    cmd_args, _ = cmd_opt.parse_known_args()
##################
##Taobao
# if dataset=='Taobao':
#     cmd_opt = argparse.ArgumentParser(description='Argparser for coevolve')
#     cmd_opt.add_argument('--dataset', type=str, default='Taobao', help='which dataset to use')
#     cmd_opt.add_argument('--aggregator', type=str, default='sum', help='which aggregator to use')
#     cmd_opt.add_argument('--n_epochs', type=int, default=10, help='the number of epochs')
#     cmd_opt.add_argument('--neighbor_sample_size', type=int, default=8, help='the number of neighbors to be sampled')
#     cmd_opt.add_argument('--dim', type=int, default=16, help='dimension of user and entity embeddings')
#     cmd_opt.add_argument('--n_iter', type=int, default=1, help='number of iterations when computing entity representation')
#     cmd_opt.add_argument('--batch_size', type=int, default=128, help='batch size')
#     cmd_opt.add_argument('--l2_weight', type=float, default=1e-4, help='weight of l2 regularization')
#     cmd_opt.add_argument('--lr', type=float, default=5e-4, help='learning rate')
#     cmd_opt.add_argument('--ratio', type=float, default=1, help='size of training dataset')
#     cmd_opt.add_argument('-train_file', default='../data/Taobao/train.txt', help='train_file')
#     cmd_opt.add_argument('-test_file', default='../data/Taobao/test.txt', help='test_file')
#     cmd_opt.add_argument('-kg_user', default=True, help='kg_user')
#     cmd_opt.add_argument('-kg_item', default=True, help='kg_item')
#
#     cmd_opt.add_argument('-metapath', default=True, help='metapath')
#     cmd_opt.add_argument('-tbatch', type=int, default=10, help='tbatch')
#     cmd_opt.add_argument('-weight_ratio', default=0.1, type=float, help='weight_ratio')
#
#     cmd_opt.add_argument('-save_dir', default='.', help='result output root')
#     cmd_opt.add_argument('-dropbox', default=None, help='dropbox folder')
#     cmd_opt.add_argument('-init_model_dump', default=None, help='model dump')
#     cmd_opt.add_argument('-data_name', default=None, help='dataset name')
#     cmd_opt.add_argument('-phase', default=None, help='phase')
#     cmd_opt.add_argument('-dt_type', default='last', help='last/cur')
#     cmd_opt.add_argument('-int_act', default='exp', help='activation function for intensity', choices=['exp', 'softplus','sigmoid'])
#     cmd_opt.add_argument('-score_func', default='log_ll', help='log_ll/comp/intensity')
#     cmd_opt.add_argument('-is_training', default=True, type=eval, help='is training')
#     cmd_opt.add_argument('-embed_dim', default=128, type=int, help='embedding dim of gnn')
#     cmd_opt.add_argument('-bptt', default=100, type=int, help='bptt size')
#     cmd_opt.add_argument('-num_items', default=0, type=int, help='num items')
#     cmd_opt.add_argument('-num_users', default=0, type=int, help='num users')
#     cmd_opt.add_argument('-maxitem', default=0, type=int, help='max item')
#     cmd_opt.add_argument('-maxuser', default=0, type=int, help='max user')
#     cmd_opt.add_argument('-neg_items', default=100, type=int, help='neg items')
#     cmd_opt.add_argument('-neg_users', default=100, type=int, help='neg users')
#     cmd_opt.add_argument('-max_norm', default=0.1, type=float, help='max embed norm')
#     cmd_opt.add_argument('-time_scale', default=0.001, type=float, help='time scale')
#     cmd_opt.add_argument('-time_lb', default=0.01, type=float, help='min time dur')
#     cmd_opt.add_argument('-time_ub', default=0.1, type=float, help='max time dur')
#     cmd_opt.add_argument('-seed', default=19260817, type=int, help='seed')
#     cmd_opt.add_argument('-learning_rate', default=0.0001, type=float, help='learning rate')
#     cmd_opt.add_argument('-grad_clip', default=5, type=float, help='clip gradient')
#     cmd_opt.add_argument('-num_epochs', default=1000, type=int, help='number of training epochs')
#     cmd_opt.add_argument('-iters_per_val', default=100, type=int, help='number of iterations per evaluation')
#     cmd_opt.add_argument('-batch_size', default=64, type=int, help='batch size for training')
#     cmd_opt.add_argument('-eval_ratio', default=0, type=float, help='eval_ratio')
#     cmd_opt.add_argument('-test_ratio', default=0.3, type=float, help='test_ratio')
#     cmd_opt.add_argument('-act', '--act', type=str, help='act function', default='tanh')
#     cmd_opt.add_argument('-hop', default=1, type=int, help='hop')
#     cmd_opt.add_argument('-path_len', type=int, default=3, help='path_len')
#     cmd_opt.add_argument('-path_sample_size', type=int, default=4, help='path_sample_size')
#     cmd_args, _ = cmd_opt.parse_known_args()



if dataset=='Taobao_Big':
    cmd_opt = argparse.ArgumentParser(description='Argparser for coevolve')
    cmd_opt.add_argument('--dataset', type=str, default='Taobao_Big', help='which dataset to use')
    cmd_opt.add_argument('--aggregator', type=str, default='sum', help='which aggregator to use')
    cmd_opt.add_argument('--n_epochs', type=int, default=10, help='the number of epochs')
    cmd_opt.add_argument('--neighbor_sample_size', type=int, default=8, help='the number of neighbors to be sampled')
    cmd_opt.add_argument('--dim', type=int, default=16, help='dimension of user and entity embeddings')
    cmd_opt.add_argument('--n_iter', type=int, default=1, help='number of iterations when computing entity representation')
    cmd_opt.add_argument('--batch_size', type=int, default=128, help='batch size')
    cmd_opt.add_argument('--l2_weight', type=float, default=1e-4, help='weight of l2 regularization')
    cmd_opt.add_argument('--lr', type=float, default=5e-4, help='learning rate')
    cmd_opt.add_argument('--ratio', type=float, default=1, help='size of training dataset')
    cmd_opt.add_argument('-train_file', default='../data/Taobao_Big/train.txt', help='train_file')
    cmd_opt.add_argument('-test_file', default='../data/Taobao_Big/test.txt', help='test_file')
    cmd_opt.add_argument('-kg_user', default=True, help='kg_user')
    cmd_opt.add_argument('-kg_item', default=True, help='kg_item')

    cmd_opt.add_argument('-metapath', default=True, help='metapath')
    cmd_opt.add_argument('-tbatch', type=int, default=10, help='tbatch')
    cmd_opt.add_argument('-weight_ratio', default=0.1, type=float, help='weight_ratio')

    cmd_opt.add_argument('-save_dir', default='.', help='result output root')
    cmd_opt.add_argument('-dropbox', default=None, help='dropbox folder')
    cmd_opt.add_argument('-init_model_dump', default=None, help='model dump')
    cmd_opt.add_argument('-data_name', default=None, help='dataset name')
    cmd_opt.add_argument('-phase', default=None, help='phase')
    cmd_opt.add_argument('-dt_type', default='last', help='last/cur')
    cmd_opt.add_argument('-int_act', default='exp', help='activation function for intensity', choices=['exp', 'softplus','sigmoid'])
    cmd_opt.add_argument('-score_func', default='log_ll', help='log_ll/comp/intensity')
    cmd_opt.add_argument('-is_training', default=True, type=eval, help='is training')
    cmd_opt.add_argument('-embed_dim', default=128, type=int, help='embedding dim of gnn')
    cmd_opt.add_argument('-bptt', default=100, type=int, help='bptt size')
    cmd_opt.add_argument('-num_items', default=0, type=int, help='num items')
    cmd_opt.add_argument('-num_users', default=0, type=int, help='num users')
    cmd_opt.add_argument('-maxitem', default=0, type=int, help='max item')
    cmd_opt.add_argument('-maxuser', default=0, type=int, help='max user')
    cmd_opt.add_argument('-neg_items', default=100, type=int, help='neg items')
    cmd_opt.add_argument('-neg_users', default=100, type=int, help='neg users')
    cmd_opt.add_argument('-max_norm', default=0.1, type=float, help='max embed norm')
    cmd_opt.add_argument('-time_scale', default=0.001, type=float, help='time scale')
    cmd_opt.add_argument('-time_lb', default=0.01, type=float, help='min time dur')
    cmd_opt.add_argument('-time_ub', default=0.1, type=float, help='max time dur')
    cmd_opt.add_argument('-seed', default=19260817, type=int, help='seed')
    cmd_opt.add_argument('-learning_rate', default=0.0001, type=float, help='learning rate')
    cmd_opt.add_argument('-grad_clip', default=5, type=float, help='clip gradient')
    cmd_opt.add_argument('-num_epochs', default=1000, type=int, help='number of training epochs')
    cmd_opt.add_argument('-iters_per_val', default=100, type=int, help='number of iterations per evaluation')
    cmd_opt.add_argument('-batch_size', default=64, type=int, help='batch size for training')
    cmd_opt.add_argument('-eval_ratio', default=0, type=float, help='eval_ratio')
    cmd_opt.add_argument('-test_ratio', default=0.3, type=float, help='test_ratio')
    cmd_opt.add_argument('-act', '--act', type=str, help='act function', default='tanh')
    cmd_opt.add_argument('-hop', default=1, type=int, help='hop')
    cmd_opt.add_argument('-path_len', type=int, default=3, help='path_len')
    cmd_opt.add_argument('-path_sample_size', type=int, default=4, help='path_sample_size')
    cmd_args, _ = cmd_opt.parse_known_args()







